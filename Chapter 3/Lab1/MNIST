# Import necessary libraries
import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.utils import to_categorical
import os
import numpy as np
import pandas as pd
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.models import Model
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt
import nibabel as nib  # For reading NIfTI files
from sklearn.preprocessing import LabelEncoder

# Step 1: Load and Preprocess the MNIST Data
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train = x_train.astype('float32') / 255
x_test = x_test.astype('float32') / 255
y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)

# Step 2: Build the Neural Network Model
model = Sequential([
    Flatten(input_shape=(28, 28)),
    Dense(128, activation='relu'),
    Dense(10, activation='softmax')
])
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Step 3: Train the Model
model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.2)

# Step 4: Evaluate the Model
test_loss, test_accuracy = model.evaluate(x_test, y_test)
print(f'Test loss: {test_loss}')
print(f'Test accuracy: {test_accuracy}')

# Step 5: Load and Preprocess the MRI Data
drive.mount('/content/drive')
participant_data_path = '/content/drive/MyDrive/Brain-MRI-Age-Classification-using-Deep-Learning/ds000228-1.1.0-subset/derivatives/participants.tsv'
participant_data = pd.read_csv(participant_data_path, sep='\t')
participant_data['AgeClass'] = pd.cut(participant_data['Age'], bins=[3, 6, 13, np.inf], labels=['Ages3-5', 'Ages7-12', 'Adults'])
mri_data_folder = '/content/drive/MyDrive/Brain-MRI-Age-Classification-using-Deep-Learning/ds000228-1.1.0-subset/derivatives/preprocessed_data'

def load_2d_slices(mri_data_folder):
    images = []
    labels = []
    missing_files = []
    for participant_str in os.listdir(mri_data_folder):
        if participant_str.startswith('sub-pixar'):
            vol_path = os.path.join(mri_data_folder, participant_str, f'{participant_str}_normed_anat.nii.gz')
            if not os.path.exists(vol_path):
                missing_files.append(vol_path)
                continue
            vol = nib.load(vol_path).get_fdata()
            mid_slice = vol[:, :, vol.shape[2] // 2]
            images.append(mid_slice)
            labels.append(participant_data.loc[participant_data['participant_id'] == participant_str, 'AgeClass'].values[0])
    return np.array(images), np.array(labels)

images, labels = load_2d_slices(mri_data_folder)
images = images[..., np.newaxis]
label_encoder = LabelEncoder()
labels_encoded = label_encoder.fit_transform(labels)
x_train, x_test, y_train, y_test = train_test_split(images, labels_encoded, test_size=0.2, stratify=labels_encoded, random_state=42)

def resize_and_convert(images):
    images_resized = []
    for img in images:
        img_resized = tf.image.resize(img, (224, 224))
        img_3ch = tf.image.grayscale_to_rgb(img_resized)
        images_resized.append(img_3ch)
    return np.array(images_resized)

x_train_3ch = resize_and_convert(x_train)
x_test_3ch = resize_and_convert(x_test)

datagen = ImageDataGenerator(rescale=1./255, rotation_range=30, zoom_range=0.2, horizontal_flip=True, validation_split=0.2)
train_gen = datagen.flow(x_train_3ch, y_train, batch_size=32, subset='training')
val_gen = datagen.flow(x_train_3ch, y_train, batch_size=32, subset='validation')

# Step 6: Transfer Learning with ResNet50
base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
x = Flatten()(base_model.output)
x = Dense(128, activation='relu')(x)
predictions = Dense(3, activation='softmax')(x)
model = Model(inputs=base_model.input, outputs=predictions)
for layer in base_model.layers:
    layer.trainable = False
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

class CustomProgbar(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        print(f"Epoch {epoch + 1}/{self.params['epochs']}")
        for key, value in logs.items():
            print(f"{key}: {value:.4f}")

model.fit(train_gen, validation_data=val_gen, epochs=10, callbacks=[CustomProgbar()])

# Step 7: Evaluate the Model
test_gen = datagen.flow(x_test_3ch, y_test, batch_size=32, shuffle=False)
y_pred = np.argmax(model.predict(test_gen), axis=1)
accuracy = accuracy_score(y_test, y_pred)
print(f'Test accuracy: {accuracy}')

# Step 8: Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', xticklabels=['Ages3-5', 'Ages7-12', 'Adults'], yticklabels=['Ages3-5', 'Ages7-12', 'Adults'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# Step 9: Occlusion Sensitivity Maps
def compute_occlusion_sensitivity_map(model, image, label, patch_size=10):
    original_pred = model.predict(image[np.newaxis, ...])[0]
    sensitivity_map = np.zeros(image.shape[:2])
    for i in range(0, image.shape[0] - patch_size + 1, patch_size):
        for j in range(0, image.shape[1] - patch_size + 1, patch_size):
            occluded_image = image.copy()
            occluded_image[i:i+patch_size, j:j+patch_size, :] = 0
            occluded_pred = model.predict(occluded_image[np.newaxis, ...])[0]
            sensitivity_map[i:i+patch_size, j+j+patch_size] = original_pred[label] - occluded_pred[label]
    return sensitivity_map

def view_occlusion_sensitivity_maps(class_label, num_images, model, x_test, y_test, y_pred):
    class_index = np.where(y_test == class_label)[0]
    correctly_classified = class_index[y_test[class_index] == y_pred[class_index]]
    selected_indices = np.random.choice(correctly_classified, num_images, replace=False)
    
    plt.figure(figsize=(15, 5 * num_images))
    for idx, img_index in enumerate(selected_indices):
        image = x_test[img_index]
        label = y_test[img_index]
        sensitivity_map = compute_occlusion_sensitivity_map(model, image, label)
        
        plt.subplot(num_images, 2, 2*idx+1)
        plt.imshow(image / np.max(image))
        plt.title(f'Original Image (Label: {label_encoder.inverse_transform([label])[0]})')
        
        plt.subplot(num_images, 2, 2*idx+2)
        plt.imshow(sensitivity_map, cmap='hot', interpolation='nearest')
        plt.title('Occlusion Sensitivity Map')
    plt.show()

class_label = label_encoder.transform(['Ages3-5'])[0]
view_occlusion_sensitivity_maps(class_label, 3, model, x_test_3ch, y_test, y_pred)

for class_name in ['Ages7-12', 'Adults']:
    class_label = label_encoder.transform([class_name])[0]
    view_occlusion_sensitivity_maps(class_label, 3, model, x_test_3ch, y_test, y_pred)
